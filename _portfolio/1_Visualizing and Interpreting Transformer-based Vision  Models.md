---
title: "Visualizing and Interpreting Transformer-based Vision  Models"
#excerpt: "This is a summary of project 1"
header:
#  image: /assets/images/unsplash-gallery-image-3.jpg
  teaser: assets/images/project_1_image.png
sidebar:
  - title: "Role"
    image:  assets/images/project_1_image.png
    image_alt: "logo"
    text: "Designer, Front-End Developer"
  - title: "Responsibilities"
    text: "Reuters try PR stupid commenters should isn't a business model"
---

Transformer-based vision models are increasingly popular and we need better ways to interpret and visualize their predictions. Previous works have been limited to visualizing attention maps; we apply a Shapley-value based method (FastSHAP) to Vision Transformers and Masked Au- toencoders, comparing the results to a classical ResNet. We find that choosing ResNet as the surrogate model for FastSHAP lets us successfully interpret and visualize transformer-based vision models. We observe that the estimated Shapley values of ResNet and ViT trained on CIFAR-10 are qualitatively different, even though the modelsâ€™ predictions are mostly consistent. Keywords: Interpretability, Visualization, Shapley values, Vision Transformer, Masked Autoen- conder

[Paper](https://roldanjrgl.github.io/files/visualizing_and_interpreting_transformer_based_vision_models.pdf)
